{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "# from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "img_width = 32\n",
    "img_height = 32\n",
    "num_classes = 10\n",
    "nb_train_samples = 10000\n",
    "nb_validation_samples = 2000\n",
    "batch_size = 16\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = './credit_card/train'\n",
    "validation_data_dir = './credit_card/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our data generator for our test data\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    # used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "    rescale = 1./255)\n",
    "\n",
    "# Creating our data generator for our training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,              # normalize pixel values to [0,1]\n",
    "      rotation_range = 10,           # randomly applies rotations\n",
    "      width_shift_range = 0.25,       # randomly applies width shifting\n",
    "      height_shift_range = 0.25,      # randomly applies height shifting\n",
    "      shear_range=0.5,\n",
    "      zoom_range=0.5,\n",
    "      horizontal_flip = False,        # randonly flips the image\n",
    "      fill_mode = 'nearest')         # uses the fill mode nearest to fill gaps created by the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 4000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Specify criteria about our training data, such as the directory, image size, batch size and type \n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use the effective and famous (on MNIST) LeNET Convolutional Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1600500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,632,080\n",
      "Trainable params: 1,632,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# 2 sets of CRP (Convolution, RELU, Pooling)\n",
    "model.add(Conv2D(20, (5, 5),\n",
    "                 padding = \"same\", \n",
    "                 input_shape = input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(50, (5, 5),\n",
    "                 padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "# Fully connected layers (w/ RELU)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Softmax (for classification)\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "           \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"./Trained Models/creditcard.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 4000\n",
    "epochs = 5\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 200s 160ms/step - loss: 0.4143 - accuracy: 0.8611 - val_loss: 0.0011 - val_accuracy: 0.9965\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 201s 161ms/step - loss: 0.1411 - accuracy: 0.9513 - val_loss: 8.0736e-04 - val_accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 154s 123ms/step - loss: 0.1042 - accuracy: 0.9654 - val_loss: 3.2346e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 160s 128ms/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 4.4151e-05 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 165s 132ms/step - loss: 0.0794 - accuracy: 0.9729 - val_loss: 6.3071e-06 - val_accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "#     callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./Trained Models/creditcard.h5\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
